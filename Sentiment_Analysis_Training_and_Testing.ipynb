{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hibahassan1/COVID19-Tweets-Sentiment-Analysis/blob/main/Sentiment_Analysis_Training_and_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i4pEUJMEa_N",
        "outputId": "0cf36452-28de-4842-a5e1-49931b3da898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ4LIfgc3yxT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IQV0QGd88kM",
        "outputId": "761b3148-e637-4c32-ade7-72c5df6c3f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DKoY3yQ9IvW"
      },
      "outputs": [],
      "source": [
        "twitter_data = pd.read_csv('/content/drive/MyDrive/covid19_tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(content):\n",
        "    content = content.lower()\n",
        "    words = re.findall(r'\\b\\w+\\b', content)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    preprocessed_content = ' '.join(lemmatized_words)\n",
        "    return preprocessed_content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOBzRbiSw8SM",
        "outputId": "0704bcb7-5420-4fb3-beb5-d0dd4c05ff97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data['preprocessed_text'] = twitter_data['Tweets'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "JPGhKCJHxE2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "Dmc6zqmPxRAd",
        "outputId": "f0cce92b-6988-4792-a723-7dbab563e9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Tweets            ID  \\\n",
              "0  Me to my  Will you with me for the rest of our...  1.320000e+18   \n",
              "1  Yes Offcourse, most of the tested people here ...  1.320000e+18   \n",
              "2  Tune in to Dubai Eye tomorrow at 4:00 pm. Ludm...  1.320000e+18   \n",
              "3  Are you sure about that sir Students died afte...  1.320000e+18   \n",
              "4       I hope Delhi government will help his family  1.320000e+18   \n",
              "\n",
              "               Date  Likes  Retweets  Sentiment  \\\n",
              "0  11/10/2020 11:20      2         1          1   \n",
              "1  11/10/2020 10:45      1         0          2   \n",
              "2   11/10/2020 6:32      0         0          1   \n",
              "3   11/10/2020 6:23      1         0          0   \n",
              "4   11/10/2020 5:53      0         0          2   \n",
              "\n",
              "                                   preprocessed_text  \n",
              "0                                          rest life  \n",
              "1  yes offcourse tested people foreigner approx 7...  \n",
              "2  tune dubai eye tomorrow 4 00 pm ludmila yamalo...  \n",
              "3  sure sir student died contracting corona atten...  \n",
              "4                  hope delhi government help family  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3e9b9fc-b3a7-4568-a4f9-55f23419ace7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "      <th>ID</th>\n",
              "      <th>Date</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>preprocessed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Me to my  Will you with me for the rest of our...</td>\n",
              "      <td>1.320000e+18</td>\n",
              "      <td>11/10/2020 11:20</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>rest life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yes Offcourse, most of the tested people here ...</td>\n",
              "      <td>1.320000e+18</td>\n",
              "      <td>11/10/2020 10:45</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>yes offcourse tested people foreigner approx 7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tune in to Dubai Eye tomorrow at 4:00 pm. Ludm...</td>\n",
              "      <td>1.320000e+18</td>\n",
              "      <td>11/10/2020 6:32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>tune dubai eye tomorrow 4 00 pm ludmila yamalo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Are you sure about that sir Students died afte...</td>\n",
              "      <td>1.320000e+18</td>\n",
              "      <td>11/10/2020 6:23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>sure sir student died contracting corona atten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I hope Delhi government will help his family</td>\n",
              "      <td>1.320000e+18</td>\n",
              "      <td>11/10/2020 5:53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>hope delhi government help family</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3e9b9fc-b3a7-4568-a4f9-55f23419ace7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3e9b9fc-b3a7-4568-a4f9-55f23419ace7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3e9b9fc-b3a7-4568-a4f9-55f23419ace7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db5b471c-3bfd-4ace-a40b-49d4cb372823\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db5b471c-3bfd-4ace-a40b-49d4cb372823')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db5b471c-3bfd-4ace-a40b-49d4cb372823 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "twitter_data",
              "summary": "{\n  \"name\": \"twitter_data\",\n  \"rows\": 15865,\n  \"fields\": [\n    {\n      \"column\": \"Tweets\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15860,\n        \"samples\": [\n          \"Iran warns of a fourth wave of Corona\",\n          \"So apparently so many people who went to Islamabad taste are tested Positive for Covid-19.\",\n          \"Corona decided to arrange a discount for the wedding before prices rise\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.552377504614262e+16,\n        \"min\": 1.31e+18,\n        \"max\": 1.41e+18,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          1.36e+18,\n          1.32e+18,\n          1.4e+18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 13987,\n        \"samples\": [\n          \"17/01/2021 4:31\",\n          \"10/02/2021 18:35\",\n          \"04/03/2021 11:42\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Likes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 0,\n        \"max\": 802,\n        \"num_unique_values\": 105,\n        \"samples\": [\n          272,\n          36,\n          350\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Retweets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 87,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          27,\n          14,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15739,\n        \"samples\": [\n          \"surviving cancer heart attack corona defeat larry king\",\n          \"guy covid guideline traveler updated anywhere last week 12 year need covid report today made mandatory 6 month made go back airport last min bcos stupidity\",\n          \"hundred briton flee quarantine switzerland\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Cross Validation to improve Accuracy\n"
      ],
      "metadata": {
        "id": "SkFOgtrbsbjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the SVM\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load your dataset and preprocess it\n",
        "# Define your features (X) and target (y)\n",
        "X = twitter_data['preprocessed_text']\n",
        "y = twitter_data['Sentiment']\n",
        "\n",
        "# Convert text data into TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "# Apply SMOTE to upsample the minority classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the SVM\n",
        "svm_model = SVC(kernel='rbf', C=10.0, gamma=1.0)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
        "\n",
        "# Fit the model on the entire training set\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
        "\n",
        "# Calculate and print accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the trained model\n",
        "# joblib.dump(svm_model, 'svm_model.pkl')\n",
        "\n"
      ],
      "metadata": {
        "id": "P7yhzgx-qO3v",
        "outputId": "6069bd3a-4c44-4330-e6ad-7c52c7717f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.76446669 0.74624531 0.74561952 0.75938673 0.75125156]\n",
            "Mean CV accuracy: 0.7533939632861376\n",
            "Accuracy: 0.7805305305305306\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.79      0.80      1355\n",
            "           1       0.70      0.73      0.71      1320\n",
            "           2       0.84      0.82      0.83      1321\n",
            "\n",
            "    accuracy                           0.78      3996\n",
            "   macro avg       0.78      0.78      0.78      3996\n",
            "weighted avg       0.78      0.78      0.78      3996\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(svm_model, 'svm_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NSECsjs7ln5",
        "outputId": "137e6b60-8887-45c0-f912-4f73eed30206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['svm_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training LR\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Define your features (X) and target (y)\n",
        "X = twitter_data['preprocessed_text']\n",
        "y = twitter_data['Sentiment']\n",
        "\n",
        "# Convert text data into TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "# Apply SMOTE to upsample the minority classes\n",
        "smote = SMOTE(random_state=2)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the Logistic Regression\n",
        "lr_model = LogisticRegression(C=3.329770563201687, penalty='l2', solver='saga', max_iter=500)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(lr_model, X_train, y_train, cv=5)\n",
        "\n",
        "# Fit the model on the entire training set\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the test set\n",
        "y_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
        "\n",
        "# Calculate and print accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the trained model\n",
        "# joblib.dump(lr_model, 'lr_model.pkl')\n"
      ],
      "metadata": {
        "id": "COONAXx7s-iX",
        "outputId": "8d242c40-23be-41f4-b7b7-9a3ac6ed79ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.71254301 0.6971214  0.69211514 0.70588235 0.68742178]\n",
            "Mean CV accuracy: 0.699016736983162\n",
            "Accuracy: 0.7112112112112112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.75      0.75      1355\n",
            "           1       0.64      0.62      0.63      1320\n",
            "           2       0.74      0.77      0.75      1321\n",
            "\n",
            "    accuracy                           0.71      3996\n",
            "   macro avg       0.71      0.71      0.71      3996\n",
            "weighted avg       0.71      0.71      0.71      3996\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Adaboost\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset and preprocess it\n",
        "# Define your features (X) and target (y)\n",
        "X = twitter_data['preprocessed_text']\n",
        "y = twitter_data['Sentiment']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data into TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "# Apply SMOTE to upsample the minority classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
        "\n",
        "# Train the AdaBoostClassifier\n",
        "adaboost_model = AdaBoostClassifier(n_estimators=200, learning_rate=1.0, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(adaboost_model, X_resampled, y_resampled, cv=5)\n",
        "\n",
        "# Fit the model on the entire resampled dataset\n",
        "adaboost_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Predict labels for the test set\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "y_pred = adaboost_model.predict(X_test_tfidf)\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
        "\n",
        "# Calculate and print accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the trained model\n",
        "# joblib.dump(adaboost_model, 'adaboost_model.pkl')\n"
      ],
      "metadata": {
        "id": "otELVI6KtiXf",
        "outputId": "f1334b5f-abf1-42ae-c378-f8cf8c5b9901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.51326326 0.55005005 0.62377972 0.67459324 0.62553191]\n",
            "Mean CV accuracy: 0.597443638882938\n",
            "Accuracy: 0.6457611093602269\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.69      1062\n",
            "           1       0.60      0.68      0.64      1275\n",
            "           2       0.63      0.59      0.61       836\n",
            "\n",
            "    accuracy                           0.65      3173\n",
            "   macro avg       0.65      0.64      0.64      3173\n",
            "weighted avg       0.65      0.65      0.65      3173\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training random forest\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n",
        "# Define your features (X) and target (y)\n",
        "X = twitter_data['preprocessed_text']\n",
        "y = twitter_data['Sentiment']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data into TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "# Apply SMOTE to upsample the minority classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
        "\n",
        "# Initialize RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(n_estimators=200,\n",
        "                                   max_depth=20,\n",
        "                                   min_samples_split=2,\n",
        "                                   min_samples_leaf=1,\n",
        "                                   max_features='sqrt',\n",
        "                                   random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(rf_model, X_resampled, y_resampled, cv=5)\n",
        "\n",
        "# Fit the model on the entire resampled dataset\n",
        "rf_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Make predictions\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "y_pred = rf_model.predict(X_test_tfidf)\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
        "\n",
        "# Calculate and print accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the trained model\n",
        "# joblib.dump(rf_model, 'rf_model.pkl')\n"
      ],
      "metadata": {
        "id": "ZY8amBYyuHcf",
        "outputId": "d28f2185-c1c7-4824-f1b7-3e74d2df899e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.47522523 0.56656657 0.60625782 0.66382979 0.60250313]\n",
            "Mean CV accuracy: 0.582876506042964\n",
            "Accuracy: 0.7046958714150646\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.62      0.70      1062\n",
            "           1       0.65      0.79      0.71      1275\n",
            "           2       0.71      0.68      0.69       836\n",
            "\n",
            "    accuracy                           0.70      3173\n",
            "   macro avg       0.72      0.70      0.70      3173\n",
            "weighted avg       0.72      0.70      0.70      3173\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and Loading the SVM model\n",
        "joblib.dump(svm_model, 'svm_model.pkl')\n",
        "loaded_model = joblib.load('svm_model.pkl')"
      ],
      "metadata": {
        "id": "vtXyr6sIpSp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Logistic Regression\n",
        "loaded_model = joblib.load('lr_model.pkl')"
      ],
      "metadata": {
        "id": "uTYyi3hqpX2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Random Forest\n",
        "loaded_model = joblib.load('rf_model.pkl')"
      ],
      "metadata": {
        "id": "oeiuYVxrpe5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Adaboost classifier\n",
        "loaded_model = joblib.load('adaboost_model.pkl')"
      ],
      "metadata": {
        "id": "iz91z2i_ukC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_print_sentiment(X_new):\n",
        "    # Initialize an empty list to store preprocessed tweets\n",
        "    preprocessed_X_new = []\n",
        "\n",
        "    # Preprocess each tweet in the list\n",
        "    for tweet in X_new:\n",
        "        preprocessed_tweet = preprocess_text(tweet)\n",
        "        preprocessed_X_new.append(preprocessed_tweet)\n",
        "\n",
        "    # Convert preprocessed tweets into vectors\n",
        "    X_new_vectors = tfidf_vectorizer.transform(preprocessed_X_new)\n",
        "\n",
        "    # Make predictions using the loaded model\n",
        "    predictions = loaded_model.predict(X_new_vectors)\n",
        "\n",
        "    # Print predictions\n",
        "    for prediction in predictions:\n",
        "        if prediction == 0:\n",
        "            print(\"Negative\")\n",
        "        elif prediction == 1:\n",
        "            print(\"Neutral\")\n",
        "        else:\n",
        "            print(\"Positive\")\n"
      ],
      "metadata": {
        "id": "uGBsvhLbIzVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = [\"What will happen to the iPhone 2020 with the Corona tragedy?\"]\n",
        "\n",
        "predict_and_print_sentiment(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-bDLp6ShFXo",
        "outputId": "a78a31dd-264d-4428-cc96-021e100a2162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = [\"I'm so grateful for the scientists and healthcare workers who are working tirelessly to fight COVID-19. Together, we will overcome this challenge. #gratitude #COVID19\"]\n",
        "# Initialize an empty list to store preprocessed tweets\n",
        "preprocessed_X_new = []\n",
        "\n",
        "# Preprocess each tweet in the list\n",
        "for tweet in X_new:\n",
        "    preprocessed_tweet = preprocess_text(tweet)\n",
        "    preprocessed_X_new.append(preprocessed_tweet)\n",
        "\n",
        "# Convert preprocessed tweets into TF-IDF vectors\n",
        "X_new_tfidf = tfidf_vectorizer.transform(preprocessed_X_new)\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "prediction = loaded_model.predict(X_new_tfidf)\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaOvnQ-smqjD",
        "outputId": "9ea0e7d0-cee2-41fc-d56b-6b29cf31336a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = [\"The latest statistics on COVID-19 cases are out. It's important to stay informed and continue following safety guidelines to protect ourselves and others. #COVID19\"]\n",
        "# Initialize an empty list to store preprocessed tweets\n",
        "preprocessed_X_new = []\n",
        "\n",
        "# Preprocess each tweet in the list\n",
        "for tweet in X_new:\n",
        "    preprocessed_tweet = preprocess_text(tweet)\n",
        "    preprocessed_X_new.append(preprocessed_tweet)\n",
        "\n",
        "# Convert preprocessed tweets into TF-IDF vectors\n",
        "X_new_tfidf = tfidf_vectorizer.transform(preprocessed_X_new)\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "prediction = loaded_model.predict(X_new_tfidf)\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaXLTVoXm4en",
        "outputId": "f54c5928-f41a-4fe2-fe61-01b89083d929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}